# ğŸ™ï¸ Speaker Recognition App

An end-to-end **Deep Learning Speaker Identification System** built with **PyTorch**, **SpeechBrain**, and **Streamlit**.  
This project identifies speakers from short audio recordings by extracting **ECAPA-TDNN embeddings**, classifying them through a **custom neural network**, and returning the **predicted speaker** in real time through an interactive web interface.

---

##  Project Overview

The objective of this project is to design a professional-grade **AI-based speaker recognition system** capable of accurately identifying speakers from voice samples.  

The system integrates advanced **feature extraction**, **deep learning classification**, and **web deployment** to demonstrate the complete lifecycle of an applied AI project â€” from research to production.

![App Screenshot](./screenshot%20of%20the%20web%20application%20working%20.png)

---

##  Getting Started

Follow these steps to set up and run the project locally.

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/ricardos-ai/speaker-recognition-app.git
cd speaker-recognition-app
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the Streamlit app
```bash
streamlit run streamlit_app.py
```

Then open your browser at ğŸ‘‰ **http://localhost:8501**

---

## âš™ï¸ Features

- Upload `.wav`, `.mp3`, or `.ogg` audio files directly through the web interface  
- Automatic audio preprocessing (resampling, normalization, padding)  
- Extraction of **speaker embeddings** using **SpeechBrainâ€™s ECAPA-TDNN** model  
- Classification with a **custom PyTorch neural network** trained on multiple speakers  
- Real-time prediction and visualization in a **Streamlit** web app  

---

## ğŸ§© Architecture Overview

```mermaid
flowchart TD
    A[Upload audio file (.wav/.mp3/.ogg)] --> B[Audio preprocessing]
    B --> C[Embedding extraction (ECAPA-TDNN)]
    C --> D[PyTorch classifier]
    D --> E[Predicted speaker output]
```

---

## Technical Details

| Component | Description |
|------------|-------------|
| **Language** | Python |
| **Frameworks** | PyTorch, SpeechBrain, Streamlit |
| **Audio Processing** | Torchaudio, Pydub |
| **Feature Extraction** | ECAPA-TDNN pretrained model |
| **Classifier** | Fully-connected PyTorch model with batch normalization |
| **Model Artifacts** | `best_speaker_classifier.pt`, `speaker_label_encoder.pkl` |
| **Interface** | Streamlit web app for real-time inference |

---

##  Project Structure

```
speaker-recognition-app/
â”‚
â”œâ”€â”€ streamlit_app.py                     # Streamlit interface
â”œâ”€â”€ -- Speaker Recognition.ipynb  # Model training & experiments
â”œâ”€â”€ best_speaker_classifier.pt           # Trained PyTorch model
â”œâ”€â”€ speaker_label_encoder.pkl            # Label encoder
â”œâ”€â”€ requirements.txt                     # Dependencies
â”œâ”€â”€ README.md                            # Project documentation
â””â”€â”€ screenshot of the web application working .png
```

---

## ğŸ§ª Model Development

- **Baseline:** Dense neural network using averaged MFCC features.  
- **Improved version:** Replaced static MFCCs with **ECAPA-TDNN embeddings** for more robust voice representations.  
- **Classifier training:** Custom feed-forward PyTorch model fine-tuned on embeddings with cross-entropy loss.  
- **Evaluation:** Tested on multiple real speakers, achieving >95% accuracy on validation data.

---

## ğŸ“Š Evaluation & Visualization

- **PCA / t-SNE** to visualize speaker embedding clusters.  
- **Confusion matrix** for per-speaker precision.  
- **Noise robustness** tests with background and varying durations.  

---

## ğŸ’» Deployment

The final model is deployed as a **Streamlit web app** for real-time usage:  
- Upload a voice sample â†’ automatic preprocessing and prediction.  
- Lightweight and deployable on **Streamlit Cloud** or **Hugging Face Spaces**.  

---

## ğŸ”¬ Future Improvements

- Add speaker **verification mode** (same/different speaker)  
- Train on larger open datasets (VoxCeleb, LibriSpeech)  
- Integrate **Voice Activity Detection (VAD)** for cleaner input handling  
- Containerize the project with **Docker** for reproducibility  

---

## ğŸ§¾ Requirements

Main dependencies:

```
torch
torchaudio
speechbrain
streamlit
pydub
numpy
scikit-learn
joblib
```

Install them via:
```bash
pip install -r requirements.txt
```

---

## ğŸ‘¨â€ğŸ’» Author

**Ricardos Abi Akar**  
AI & Analytics Engineer â€” MSc in Data Science & AI Strategy @ emlyon business school | Ã‰cole 42  
ğŸ”— [GitHub: ricardos-ai](https://github.com/ricardos-ai)  
ğŸ’¼ [LinkedIn: ricardos-abi-akar](https://linkedin.com/in/ricardos-abi-akar)

---

â­ **If you find this project interesting, donâ€™t forget to give it a star!**
